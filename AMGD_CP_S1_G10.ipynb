{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45e32014",
   "metadata": {},
   "source": [
    "# 0ï¸âƒ£ Initialize environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c86ba5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŸ¦ Installing Libraries\n",
      "âœ… Installing numpy\n",
      "âœ… Installing pandas\n",
      "âœ… Installing matplotlib\n",
      "âœ… Installing seaborn\n",
      "\n",
      "\n",
      "ðŸŸ¦ List Environment\n",
      "âœ… numpy Version: 2.3.1\n",
      "âœ… pandas Version: 2.3.1\n",
      "âœ… matplotlib Version: 3.10.3\n",
      "âœ… seaborn Version: 0.13.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Installing the required libraries\n",
    "import subprocess\n",
    "import sys\n",
    "print(\"ðŸŸ¦ Installing Libraries\")\n",
    "print(\"âœ… Installing numpy\")\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"numpy\"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "print(\"âœ… Installing pandas\")\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"pandas\"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "print(\"âœ… Installing matplotlib\")\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"matplotlib\"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "print(\"âœ… Installing seaborn\")\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"seaborn\"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "# Importing the libraries\n",
    "import pandas as pandas\n",
    "import numpy as numpy\n",
    "import matplotlib as matplotlib\n",
    "import seaborn as seaborn\n",
    "from importlib.metadata import version\n",
    "import matplotlib.pyplot as pyplot\n",
    "import datetime\n",
    "import random\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "# Printing the versions of the environment\n",
    "print(\"\", end=\"\\n\\n\")\n",
    "print(\"ðŸŸ¦ List Environment\")\n",
    "subprocess.run([sys.executable, \"--version\"])\n",
    "subprocess.run([sys.executable, \"pip\", \"--version\"])\n",
    "print(f\"âœ… {numpy.__name__} Version: {version(numpy.__name__)}\")\n",
    "print(f\"âœ… {pandas.__name__} Version: {version(pandas.__name__)}\")\n",
    "print(f\"âœ… {matplotlib.__name__} Version: {version(matplotlib.__name__)}\")\n",
    "print(f\"âœ… {seaborn.__name__} Version: {version(seaborn.__name__)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3104ad4f",
   "metadata": {},
   "source": [
    "# 1ï¸âƒ£ Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f55386",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Downloading the file\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "filenameUri = \"TBD\"\n",
    "dataDir = \"Data\"\n",
    "compressedFilename = \"Data.zip\"\n",
    "csvFilename = \"Data.csv\"\n",
    "\n",
    "# Downloading and Unzipping data file \n",
    "def DownloadFile(uri: str, filename: str):\n",
    "    try:\n",
    "        respuesta = requests.get(uri)\n",
    "        respuesta.raise_for_status() \n",
    "        with open(filename, 'wb') as archivo:\n",
    "            archivo.write(respuesta.content)\n",
    "        print(f\"File {filename} was downloaded successfully.\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading file: {e}\")\n",
    "\n",
    "def UnzipFile(filename: str, outputDir: str):\n",
    "    try:\n",
    "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall(outputDir)\n",
    "        print(f\"Unzipped to: {os.path.abspath(outputDir)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "DownloadFile(filenameUri, f\"{dataDir}/{compressedFilename}\")\n",
    "UnzipFile(f\"{dataDir}/{compressedFilename}\", f\"{dataDir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092d7415",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xa3 in position 227179: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mpandas\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mData/Online_Retail.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(df.head())\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(df.describe())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Megam\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Megam\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Megam\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Megam\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:838\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:905\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:2053\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:325\u001b[39m, in \u001b[36mdecode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'utf-8' codec can't decode byte 0xa3 in position 227179: invalid start byte"
     ]
    }
   ],
   "source": [
    "def LoadCsvWithDetectedEncoding(filePath, byteSampleSize=100000):\n",
    "    with open(filePath, 'rb') as file:\n",
    "        detectionResult = chardet.detect(file.read(byteSampleSize))\n",
    "        encoding = detectionResult['encoding']\n",
    "        print(f\"Detected encoding: {encoding}\")\n",
    "\n",
    "    df = pandas.read_csv(\"Data/Online_Retail.csv\")\n",
    "    return df\n",
    "df = LoadCsvWithDetectedEncoding(\"Data/Online_Retail.csv\")\n",
    "print(\"ðŸŸ¦ DataFrame Information\")\n",
    "print(df.head())\n",
    "print(df.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
